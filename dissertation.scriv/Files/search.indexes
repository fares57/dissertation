<?xml version="1.0" encoding="UTF-8"?>
<SearchIndexes Version="1.0">
    <Documents>
        <Document ID="2169599F-99D8-4549-B6FC-C5C5F8C75DDA">
            <Title>Notes on Seikh's Work</Title>
            <Text>Comments are directly affected by the post type
Likes are not directly affected by the post type
Hash tags are not directly affected by the post type
like is not directly affected by the word count
Comments are not affected by word count
Hash tags are affected by word count
Likes are negative affected by SMOG
Comments are negatively affected by SMOG
Hash tags are affected by SMOG but this metric will may not be used because “#” may have affected the readability ratings
Likes are affected by Flesch
Comments are affected by Flesch
</Text>
        </Document>
        <Document ID="2224D433-7CA8-43B4-9E8B-5FA21EB234CD">
            <Title>Statistical Analysis</Title>
        </Document>
        <Document ID="5DE5963D-AA84-4A40-B5F6-7222D0958D28">
            <Title>Facebook Scrape</Title>
            <Text>Facebook Scraping
Restricions
Facebook scraping was the major goal. Unfortunately we run into problems because of the way the FB website is designed. Facebook has been developed with a very protective approach. Thus, scraping data is a very hard procedure. 
When it comes to scraping profiles, there are some apps out there that can do the job of mining basic information that is being given freely by the people. Such applications are Octoparse, Phantomburst and others. Same thing happens with Facebook groups where you can mine public posts and comments by users.
Unfortunately, this doesn’t happen with Facebook Pages. For unknown reasons, Facebook pages’ data are not being served freely by Facebook’s API and hence, no free or paid web software gave us the opportunity to mine such data, nor were we able to serve ourselves from their API. The only think you can have from Pages API is posts data from pages you actually own or control. Being the moderator of the biggest Pharma FB pages was beyond the scope of this dissertation!
Under such circumstances, there was no other way but to create a scraper. A nice tool is the webscraper chrome plugin which has a very easy to use interface that let’s you mine data and make automations. Another tool that we used for scraping was octoparse. 
Octoparse has a windows based interface where you select elements and octoparse automatically scrapes all the elements like the ones you selected.This way, you can easily and without any coding knowledge automate a procedure and scrape almost any website you want. But Facebook has some irregularities. First of all, Facebook has random class names for its posts. This way you cannot dictate any class name to be scraped because no element has the same name in the html structure. Octoparse has some AI mechanisms and it managed to understand the similarities but up to a point. We still had a major loss of scraped elements.
Webscraper Chrome plugin was much better at this job, finding all elements after an automatic scrape to the bottom. But then, then problem was that we couldn’t have the like, comment and share count aligned with each element. The results were terrible and it was impossible to continue with this tool.
Another alternative would be to scrape data by ourselves using Python modules but we wouldn’t be able to bypass the 2FA and confirmation procedures of FB with a testing browser (selenium).
The last resort was to device some vanilla Javascript directives in order to scrape that data. We managed to get the correct information for each post but then, the problem was that as the chrome browser was automatically scrolling, the Facebook was creating the new posts on the fly and we couldnt reference them. The result was dissapointing and the only way we could solve was maybe trying an sync auto scrolling function with delays but due to the lack of time we had to abandon the FB data mining.</Text>
        </Document>
        <Document ID="75CB004A-FFDB-4E73-BE8B-0052EC133B76">
            <Title>Scrapes</Title>
        </Document>
        <Document ID="7882929E-AB7F-443F-B363-07250D5C53C5">
            <Title>Linkedin Scraping</Title>
            <Text>Linkedin Scraping
Linkedin was the number one choice for statistical analysis. Even though we are using data extracted through images with the help of the Google Vision API and Instagram is the king of images, we prefered Linkedin because it’s a much more demanding social network for the companies. Furthermore, there is virtually no pharma company out there without a Linkedin Account.
After all instagram accounts were not that frequent and twitter has the text’s word count limitation and pictures were not that aboundant. Therefore we targeted Linkedin for combining the best of both and shows the most profesisonal character, while we found easy ways to mine the data. After all, we knew that linkedin accounts served as “default” social media accounts and any content posted there had a big chance of being shared in other platforms as well.
Tools and procedure
The initial data mining procedure was pretty simple and straightforward. No coding was needed at all as Phantombuster.com was chosen to do the work for us. The URLs of the linkedin accounts of 24 companies were fed as a CSV file into an already made phantombuster extractor (named “LinkedIn Activities Extractor”). The companies used were:
Companies mined

abbott  
amgen 
astellaspharmainc 
astrazeneca 
basf 
baxter healthcare 
bayer 
beiersdorf 
boehringer ingelheim 
bristol myers squibb 
chiesi group 
eli lilly
gilead sciences 
glaxosmithkline 
janssen pharmaceutical companies of johnson and johnson 
leo pharma 
merck 
merck group 
novartis 
novo nordisk 
pfizer 
roche 
sanofi 
ucb pharma 


As a result, phantombuster returned a csv file, containing 6924 rows, i.e. one for each post of all the companies along with the following data:

profileUrl
This is the last part of the full linkedin account url, practically it is the name of the company
error
this is a field returning any errors, but actually returned none
timestamp
This is the time and date that mining happened. Example value: 2022-02-05T15:39:14.366Z
postUrl
This is the post's URL around which most of the processing happened until we came up with the final SPSS data
action
This field returned only the &quot;Post&quot; value and thus, was never used
imgUrl
The URL of the image of the post. Article, text, video and poll types, returned blank cells
type
The type of the post. Possible values: Article, image, poll, text, live video, video (external source), video (internal source)
postContent
The filed containing the string of the text of the post.
likeCount
The count of likes each post received
commentCount
The count of comments each post received
postDate
The date of the post. Unfortunately linkedin returned d/m/y before present day so no seasonality could be taken into account
viewCount
This field returns the number of views a post received. Since no account was belonging to us, there were no rights and we got only blanks

These data acted as a base for the rest of the mining regarding image and text properties.
Readability
Next step was to calculate the readability for each post’s content. For this, we used another web service, called https://readable.com/. Readable offers a wide range of readability indices but we chose to use SMOG (because USDA advices the use of it in the drugs’ leaflets) and Flesch Kincaid Grade Level because it’s the most popular and SMOG is not very accurate with small texts.

Again, a CSV with the content of each post was fed (wherever text content existed) to the platform and a final CSV with all the indices was returned from which only SMOG and Flesch were used as explained above.
Vision API
We then had to process the images for colors, faces and emotions. Google has a great service for all of these, named “Vision API”. We used python to extract these information.
More specifically, one python script was devised in order to extract the faces number (if any) in all of the pictures. 
Another one was written so we could fetch the feelings in the faces of each picture. Vision API returned a possibility for each of four feelings inside each photo for every face there. The 4 feelings are: Joy, Angry, Sorrow and Surprice. These data were not well suited for SPSS so we dicided to manipulate in an excel file and the final SPSS data had a boolean field for the presence of each of the 4 feelings. This means that if even 1 face in a picture had a possibility or certainty of showing Joy, then Joy field was True. Same for the rest of the feelings.
After the feelings and the number of faces, we started mining color information. Vision Api has another endpoint that returns the 5 dominant colors of each picture. Again, as with faces numbers and feelings, a TXT file with the imageURLs was parsed by a python script and then was fed into the Vision Api for processing. Again, because of SPSS limitations, we kept only the most dominant color in hex format. Of course the result was thousands of unique HEX colorcodes that could not offer anything in any statistical analysis. This is where we realised that we had to classify the colors. The creation of 

</Text>
        </Document>
        <Document ID="7B619649-215D-4F7C-8771-18C7431F9644">
            <Title>Linkedin Scrape notes</Title>
            <Text>Linkedin Scrape Specifications and Constrains
Things Scraped
Some of the following variables are either not needed or without consistency, hence, they have been stricken through to signify that they will not be used for statistical analysis.

Compay Name - Profile URL : This Variable shows the name of the account that posted
Error
Timestamp : This variable shows the date that the scrape happened
PostUrl: The URL with the posst that got scraped
Action: takes only the ‘post’ value
ImgUrl: The url with the image been posted
Type: shows the type of the post
article
image
Live video
poll
text
Video (external source)
Video (linkedin source)
Word count: how many words is this post
PostContent: The main text. Even though this variable will not be imported in the SPSS file, it will be used for readability scores and sentiment analysis.
LikeCount: How many likes did the post get 
CommentCount: How many comments did the post get
PostDate: Date of the post. Unfortunately linkedin does not return a valid date format but only how months ago did this post happen
ViewCount
SMOG: This variable analyzes the SMOG readability index rating. int
SMOG diffuculty: grouped: easy/medium/hard
Flesch-Kincaid: Another readability index Variable. int
Flesch-Kincaid difficulty: easy/medium/hard
Agreement between readability ratings 
Faces exist? : 1 for yes, 0 for no
Faces Number: How many faces are in a picture (blanks = not accesssible = reposted)
Feelings in photos
Joy in picture: 1: at least 1 face with joy likely and more, 0 if not
Anger in picture: 1: at least 1 face with Anger likely and more, 0 if not
Sorrow in picture: 1: at least 1 face with Sorrow likely and more, 0 if not
Surprise in picture: 1: at least 1 face with Surprise likely and more, 0 if not
Phototext: Is there text in the photo? 1 if yes, 0 if no
Phototext word count: How many words? ints
Phototext brand: Does it contain the brand of the company? 1 if yes, 0 if no
Color: dominant color: hex value (string)
Hashtags: how many hashtags?
Constrains
Images analyzed will be only from posts that contain an image
Talk about not accessible (due to reposting)
Talk about wrong color code (unknown error during the downloading of data)
Research Questions
Is there a difference in engagement metrics by the type of post?
Do images in posts increase engagement? (compare image and non image posts for engagement)
How many pictures show a logo?
Which companies have a logo the most?
How does logo placement affect engagement?
Which colors are the most frequent on the companies’ logos?
Average word count on each image?
Percentage of images that contain the brand in text
Correlation between engagement and possible mask on image</Text>
        </Document>
        <Document ID="835BCD71-B6CD-4DB4-8F40-EAC35599488C">
            <Title>Bibliography</Title>
            <Text>National Institutes of Health (NIH). (2015, May 8). Audience-appropriate information and communicating effectively with people with limited health literacy skills. National Institutes of Health (NIH). https://www.nih.gov/institutes-nih/nih-office-director/office-communications-public-liaison/clear-communication/clear-simple 


</Text>
        </Document>
        <Document ID="9077913A-143A-489C-A217-D0A70003E026">
            <Title>Instagram Scrape notes</Title>
            <Text>Instagram Scrape Specifications and Constrains
Things Scraped
PostUrl
description
commentCount
likeCount
pubDate
likedByViewer
isSidecar
type
videoUrl
viewCount
profileUrl
username
fullName
imgUrl
postId
timestamp
query
taggedFullName1
taggedUsername1
taggedFullName2
taggedUsername2
SMOG: This variable analyzes the SMOG readability index rating
Flesch-Kincaid: Another readability index Variable
Faces: How many faces are in a picture
Anger: How likely anger exists
Sorrow: How likely sorrow exists
Joy: How likely joy exists
Surprise: How likely surprise exists
Phototext: Is there text in the photo?
Phototext word count: How many words?
(Phototext brand: Does it contain the brand of the company?)
Color: dominant color
Constrains
Carousels take only the first picture
Research Questions</Text>
        </Document>
        <Document ID="B196AFE4-BDA7-4712-B820-C49C3993A334"/>
        <Document ID="CEA5B0D1-B201-4044-9DC4-3D1BD77C42C7">
            <Title>upwork</Title>
            <Text>Hello James! 

This is the final Excel for you. Please translate all the included values to SPSS according to your needs. (final-sheet.xls)

Also, you can get ideas from the chapters 5 and 6 of a well written similar dissertation (final draft DE_MBA_Vasileiadou (3).pdf)

Below are the explanations of each column of the final-sheet.xls file

Company Name: This is the name of the company that made the post
postUrl: This is the URL of the post
Type: The type of the post (article, image, live video etc)
word count: Number of words of the POST TEXT
likeCount: Number of likes that this post received
commentCount: Number of comments that this post received
SMOG: Smog readability index raw number in float
SMOG RANK: Smog index classified as easy, medium, hard 
Flesch Kincaid Grade Level: Flesch readability index raw number in float
Flesch Kincaid RANK: Flesch index classified as easy, medium, hard
Agreement between readability ratings
faces no: Number of faces discovered in the image of the picture of the post (max 10)
face exist: If at least 1 face exists in the image
SORROW: If at least a sorrowful face exists
SURPRICE: If at least a surprised face exists
JOY: if at least a joyful face exists
ANGER: if at least an angry face exists
Text Existance in Photo: If the photo has text in it
Image Text Word Count: how many words is the IMAGE TEXT
Brand Name in Photo Text: If there is the name of this company in the image text
Dominant Color Names in Image: The name of the dominant color in this image
Number of Hashtags in Post Text: How many hashtags are in the POST TEXT.

We'd like all the above as parts of various statistical analyses. 
Please study the data and suggest us hypotheses and research questions so we can come up with the final questions so you can begin. 

thank you.</Text>
        </Document>
        <Document ID="E471F7BB-3E22-4270-9E98-B545E8D2733F">
            <Title>writing</Title>
        </Document>
        <Document ID="F14F803E-BA9D-4AC9-8B36-C756AF2D69B2">
            <Title>Research Hypotheses</Title>
            <Text>Research Hypotheses

</Text>
        </Document>
    </Documents>
</SearchIndexes>

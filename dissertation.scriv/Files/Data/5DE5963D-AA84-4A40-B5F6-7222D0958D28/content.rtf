{\rtf1\ansi\ansicpg1252\uc1\deff0
{\fonttbl{\f0\fmodern\fcharset0\fprq2 SitkaText;}{\f1\fnil\fcharset0\fprq2 SitkaText;}}
{\colortbl;\red0\green0\blue0;\red255\green255\blue255;\red128\green128\blue128;}
\paperw12240\paperh15840\margl1800\margr1800\margt1440\margb1440\f0\fs24\cf0
\pard\plain \tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\sb260\sl262\slmult1\ltrch\loch {\f1\fs36\b1 <$Scr_Ps::0><$Scr_H::1>Facebook Scraping}
\par\plain {\f1\fs36\b1\i0 Restricions<!$Scr_H::1><!$Scr_Ps::0>}
\par\pard\plain \tx0\tx360\tx720\tx1080\tx1440\tx1800\tx2160\tx2880\tx3600\tx4320\fi360\ltrch\loch {\f0\fs24\b0\i0 Facebook scraping was the major goal. Unfortunately we run into problems because of the way the FB website is designed. Facebook has been developed with a very protective approach. Thus, scraping data is a very hard procedure. }
\par\plain {\f0\fs24\b0\i0 When it comes to scraping profiles, there are some apps out there that can do the job of mining basic information that is being given freely by the people. Such applications are Octoparse, Phantomburst and others. Same thing happens with Facebook groups where you can mine public posts and comments by users.}
\par\plain {\f0\fs24\b0\i0 Unfortunately, this doesn\loch\af0\hich\af0\dbch\af0\uc1\u8217\'92t happen with Facebook Pages. For unknown reasons, Facebook pages\u8217\'92 data are not being served freely by Facebook\u8217\'92s API and hence, no free or paid web software gave us the opportunity to mine such data, nor were we able to serve ourselves from their API. The only think you can have from Pages API is posts data from pages you actually own or control. Being the moderator of the biggest Pharma FB pages was beyond the scope of this dissertation!}
\par\plain {\f0\fs24\b0\i0 Under such circumstances, there was no other way but to create a scraper. A nice tool is the webscraper chrome plugin which has a very easy to use interface that let\loch\af0\hich\af0\dbch\af0\uc1\u8217\'92s you mine data and make automations. Another tool that we used for scraping was octoparse. }
\par\plain {\f0\fs24\b0\i0 Octoparse has a windows based interface where you select elements and octoparse automatically scrapes all the elements like the ones you selected.This way, you can easily and without any coding knowledge automate a procedure and scrape almost any website you want. But Facebook has some irregularities. First of all, Facebook has random class names for its posts. This way you cannot dictate any class name to be scraped because no element has the same name in the html structure. Octoparse has some AI mechanisms and it managed to understand the similarities but up to a point. We still had a major loss of scraped elements.}
\par\plain {\f0\fs24\b0\i0 Webscraper Chrome plugin was much better at this job, finding all elements after an automatic scrape to the bottom. But then, then problem was that we couldn\loch\af0\hich\af0\dbch\af0\uc1\u8217\'92t have the like, comment and share count aligned with each element. The results were terrible and it was impossible to continue with this tool.}
\par\plain {\f0\fs24\b0\i0 Another alternative would be to scrape data by ourselves using Python modules but we wouldn\loch\af0\hich\af0\dbch\af0\uc1\u8217\'92t be able to bypass the 2FA and confirmation procedures of FB with a testing browser (selenium).}
\par\plain {\f0\fs24\b0\i0 The last resort was to device some vanilla Javascript directives in order to scrape that data. We managed to get the correct information for each post but then, the problem was that as the chrome browser was automatically scrolling, the Facebook was creating the new posts on the fly and we couldnt reference them. The result was dissapointing and the only way we could solve was maybe trying an sync auto scrolling function with delays but due to the lack of time we had to abandon the FB data mining.}}